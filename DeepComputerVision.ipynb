{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Deep Computer Vision\n",
    "\n",
    "In this guide we will learn how to peform *image classification and object detection/recognition* using deep computer vision with something called a **convolutional neural network**.\n",
    "\n",
    "The goal of our convolutional neural networks will be to classify and detect images or specific objects from within the image. We will be using image data as our features and a label for those images as our label or output.\n",
    "\n",
    "We already know how neural networks work so we can skip through the basics and move right into explaining the following concepts.\n",
    "- Image Data\n",
    "- Convolutional Layer\n",
    "- Pooling Layer\n",
    "- CNN Architectures\n",
    "\n",
    "The major differences we are about to see in these types of neural networks are the layers that make them up."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Image Data\n",
    "So far, we have dealt with pretty straight forward data that has 1 or 2 dimensions. Now we are about to deal with image data that is usually made up of 3 dimensions. These 3 dimensions are as follows:\n",
    "- image height\n",
    "- image width\n",
    "- color channels\n",
    "\n",
    "The only item in the list above you may not understand is **color channels**. The number of color channels represents the depth of an image and coorelates to the colors used in it. For example, an image with three channels is likely made up of rgb (red, green, blue) pixels. So, for each pixel we have three numeric values in the range 0-255 that define its color. For an image of color depth 1 we would likely have a greyscale image with one value defining each pixel, again in the range of 0-255.\n",
    "\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure1.png)\n",
    "\n",
    "Keep this in mind as we discuss how our network works and the input/output of each layer. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convolutional Neural Network\n",
    "**Note:** I will use the term *convnet* and convolutional neural network interchangably.\n",
    "\n",
    "Each convolutional neural network is made up of one or many convolutional layers. These layers are different than the *dense* layers we have seen previously. Their goal is to find patterns from within images that can be used to classify the image or parts of it. But this may sound familiar to what our densly connected neural network in the previous section was doing, well that's becasue it is. \n",
    "\n",
    "The fundemental difference between a dense layer and a convolutional layer is that dense layers detect patterns globally while convolutional layers detect patterns locally. When we have a densly connected layer each node in that layer sees all the data from the previous layer. This means that this layer is looking at all the information and is only capable of analyzing the data in a global capacity. Our convolutional layer however will not be densly connected, this means it can detect local patterns using part of the input data to that layer.\n",
    "\n",
    "*Let's have a look at how a densly connected layer would look at an image vs how a convolutional layer would.*\n",
    "\n",
    "This is our image; the goal of our network will be to determine whether this image is a cat or not.\n",
    "![alt text](https://img.webmd.com/dtmcms/live/webmd/consumer_assets/site_images/article_thumbnails/reference_guide/cat_weight_ref_guide/1800x1200_cat_weight_ref_guide.jpg)\n",
    "\n",
    "**Dense Layer:** A dense layer will consider the ENTIRE image. It will look at all the pixels and use that information to generate some output.\n",
    "\n",
    "**Convolutional Layer:** The convolutional layer will look at specific parts of the image. In this example let's say it analyzes the highlighted parts below and detects patterns there.\n",
    "![alt text](https://drive.google.com/uc?export=view&id=1M7v7S-b-zisFLI_G4ZY_RdUJQrGpJ3zt)\n",
    "\n",
    "Can you see why this might make these networks more useful?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}